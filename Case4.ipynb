{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please describe here *briefly* **\n",
    "\n",
    "\n",
    "1) Your business problem to solve:\n",
    "\n",
    "Brand creation and growth present unique challenges in the age of the Internet. On the one hand, the Internet provides a multitude of opportunities for content distribution and access to global audiences. On the other, the speed, low cost of distribution, and finite attention span of any individual potential consumer of digital content present new, unique challenges for new artists who seek to find an audience for their work through digital media.\n",
    "\n",
    "For emerging artists without commercial support, there exists a challenge of how to build their brand, manage their online presence, and identify important target audiences and   trends in a cost-effective way. Even though digital distribution and rating platforms can       efficiently distribute content, these systems do not necessarily provide guidance for how a new artist can attract attention on them.\n",
    "\n",
    "Artists supported by business interests benefit from extensive support, including brand management teams comprised of image consultants, digital content advisors, and artistic mentors. In order to compete with more established artists supported by these resources, new artists need to find ways to cost-effectively build their personal brand, manage their online presence, and stay on top of important cultural trends. Emerging artists could therefore benefit from a targeted data science service that reports information on regional markets and cultural trends related to their area of focus.\n",
    "\n",
    "For this case study, we have developed such a data science product that analyzes SoundCloud data to generate cost-effective business intelligence.\n",
    "\n",
    "2) Why the problem is important to solve?\n",
    "\n",
    "Using our data analysis product, musicians can target audiences and define themselves in the context of the most important and current trends in the music industry. This idea certainly deserves investment. We provide business intelligence for emerging artists at a much lower cost than a conventional brand management team. Independent artists are important and unique voices. Each artist offers a unique perspective and creative vision. In order for each artist to have the best chance of success, they need insightful support. We propose to sell a product that provides that support as a competitive price point and with opportunities for build-out advertising and online sales services.\n",
    "\n",
    "3) What is your idea to solve the problem?\n",
    "\n",
    "For this case study, we have developed such a data science product that analyzes SoundCloud data to generate cost-effective business intelligence. The information available from our service can be used to identify distribution targets, refine branding, and enhance marketing of new music. We propose to provide a subscription service offering a country-wide interactive summary of popular music genres by city location, together with a summaries of genre-specific user-generated meta-data identifying evolving terminologies and cultural themes.\n",
    "\n",
    "4) What differences you could make with your data science approach?\n",
    "\n",
    "The difference between our data science approach and other music exchange and listening platforms currently available on the internet is that the focus of our site is on providing information that allows artists to identify regional genre preferences as the same time that we present user-generated tag meta-data. What tags are generated by music fans of the same genre in different cities? Are tags highlighting new cross-genre collaborations? Are tag themes similar across genres? These types of questions can be explored easily and intuitively using our visualization platform.\n",
    "\n",
    "5) Why do you believe the idea deserves the investment of the \"sharks\"?\n",
    "\n",
    "In the United States, the music industry generated 3.9 billion dollars in 2016 alone, according to numbers reported by the Recording Industry Association of America (RIAA). Streaming services accounted for greater than 50 percent  of this revenue. There exists an enornmous market for digital music consumption – these practices both generate large volumes of consumer data for ongoing analysis and highlight the tremendous opportunities for artists who can create and grow a digital presence. We request from the sharks funding to support 6 months of salary for five full-time    extremely talented data scientists and web site fees 400,000 dollars.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: The Math Part (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the business problem as a math problem and design a math solution to the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert your answers here**\n",
    "\n",
    "1) Problem formulations in Math:  \n",
    "\n",
    "A chi-squared goodness of fit statistical test was run on the top genre in each city of our dataset. We wanted to test if our genre samples from SoundCloud were representative of the true music preferences within those cities. Since the true distributions are difficult to obtain, we assume that the genres are equally popular in each major city, but with more data from different sources, the expected distributions will become more accurate. The observed frequencies of the chi-squared test were how many times a city's top genre appeared and the city's total number of favorited tracks; the expected frequencies were 1 and the number of genres appearing in that city, converted to probabilities summing to 1.\n",
    "\n",
    "Another statistic we used was the Term frequency–inverse document frequency (TF-IDF), which calculates the importance of a term within a lexicon and its weight value. This helped us identify common and eye-catching language within the genre and location fields.\n",
    "\n",
    "2) Math Solutions:\n",
    "\n",
    "As we expected due to the lack of data, our p-values for the chi-squared goodness of fit tests were close to 0, meaning that the observed and expected frequencies are not from the same distribution. In other words, our top genre is not a good representation of the actual top genre in each city. However, gathering better population data, possibly from web scraping other location-based music sales or streaming datasets, would yield better results in future work.\n",
    "\n",
    "Zipf's Law was implemented to identify appropriate ranks for the top tags.\n",
    "\n",
    "3) Implementation of the Solutions:\n",
    "Our team used the scipy library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>genres_list</th>\n",
       "      <th>tags_list</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>['Hip-hop &amp; Rap', 'Hip-hop &amp; Rap', 'Hip-hop &amp; ...</td>\n",
       "      <td>['\"Eyes Closed\" \"Johnny Yukon\" Gizzle Invincib...</td>\n",
       "      <td>76718083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miami</td>\n",
       "      <td>['Latin']</td>\n",
       "      <td>['Bachata Vallenato BachatadeAcordeon Colombia...</td>\n",
       "      <td>53551113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brooklyn</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>260489226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winston Salem</td>\n",
       "      <td>['Rock', 'Classical', 'Classical', 'Classical'...</td>\n",
       "      <td>['sunfold \"kenny florence\"', 'Classical \"Derek...</td>\n",
       "      <td>85065739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united states</td>\n",
       "      <td>['Pop']</td>\n",
       "      <td>['\"Dance Pop\"', 'soundcloud:source=web-record ...</td>\n",
       "      <td>105357326.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city                                        genres_list  \\\n",
       "0       Maryland  ['Hip-hop & Rap', 'Hip-hop & Rap', 'Hip-hop & ...   \n",
       "1          miami                                          ['Latin']   \n",
       "2       brooklyn                                                 []   \n",
       "3  Winston Salem  ['Rock', 'Classical', 'Classical', 'Classical'...   \n",
       "4  united states                                            ['Pop']   \n",
       "\n",
       "                                           tags_list      user_id  \n",
       "0  ['\"Eyes Closed\" \"Johnny Yukon\" Gizzle Invincib...   76718083.0  \n",
       "1  ['Bachata Vallenato BachatadeAcordeon Colombia...   53551113.0  \n",
       "2                                                 []  260489226.0  \n",
       "3  ['sunfold \"kenny florence\"', 'Classical \"Derek...   85065739.0  \n",
       "4  ['\"Dance Pop\"', 'soundcloud:source=web-record ...  105357326.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###CASE STUDY 4####\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "loc=\"C:/WPI/DS501/CaseStudy/CaseStudy4/\"\n",
    "file=loc+'soundcloud.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "chicago = ['Chicago','Chicago IL and Anaheim Ca','CHICAGO IL, The Almighty WestSide','Chicago Illinois','Chicago, Illinois','Chicago/Albuquerque/Stuttgart','Chicagoland']\n",
    "miami = ['Fort Lauderdale / Miami Beach area in Florida','miami','MIAMI','Miami Beach','Miami Beach - Florida','Miami Beach / Los Angeles /','Miami,Fl']\n",
    "houston = ['Houston','Houston, Texas','Houston ','HOUSTON TEXAS','Houston Tx','houston,texas,united states','Houston`','PORT ARTHUR/HOUSTON/LOS ANGELES/DALLAS/HAMPTON VA.']\n",
    "denver= ['Denver','Denver, CO','Denver','Denver, Colorado']\n",
    "nashville= ['Nashville','Nashville','NASHVILLE, TENNESSEE','Nashville, TN']\n",
    "DC=['Washington DC','Washington, D.C.','Washington D.C.','Washington, DC','Washington D. C.','Washington, D.C','washington,d.c']\n",
    "boston = ['Boston','Boston, Texas','Boston MA ,United states','Boston, Massachusetts - Austin, Texas','Boston, Massachusetts ','BOSTON','Boston, Massachusetts']\n",
    "la= ['Los Angeles, CA','Los Angeles','L.A','Los Angeles Area','Los Angeles, California','Los Angeles // Santa Barbara','los angeles','Los Angeles, California','LOS ANGELES','LosAngeles','Los Angeles, CA + Phoenix, AZ']\n",
    "nyc = ['New York','New York City','NYC','new york city','New York & Philadelphia','New York, NY','NEW YORK','New York/ L.A.','NY']\n",
    "new_orl = ['New Orleans','New Orleans, Louisiana','The World via New Orleans']\n",
    "pheon = ['Phoenix','Los Angeles, CA + Phoenix, AZ','Phoenix, AZ']\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#EXPORT JSON FILE\n",
    "#invar=variable containing data to be converted to json\n",
    "#filename=file name for the json data to be save to\n",
    "##################  START   ############################################\n",
    "def json_export(invar,filename):\n",
    "    data=invar.reset_index().to_json(orient='records')\n",
    "    file = open(filename,'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    return(data)\n",
    "###################  END  ##################################################\n",
    "    \n",
    "    \n",
    "#####################################################################\n",
    "#Extract info from raw file\n",
    "##################  START   ############################################    \n",
    "\n",
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]\n",
    "          \n",
    "\n",
    "    \n",
    "    \n",
    "def vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range):\n",
    "    vectorizor=TfidfVectorizer(doc,max_features=val_max_feature,\n",
    "                           min_df=val_min_df,max_df=val_max_df,\n",
    "                           stop_words='english',\n",
    "                           ngram_range=val_ngram_range)\n",
    "\n",
    "    tfid_result=vectorizor.fit_transform(doc)\n",
    "    top_tags=display_scores(vectorizor,tfid_result)\n",
    "    \n",
    "    return(top_tags)\n",
    "\n",
    "\n",
    "def display_scores(vectorizer, tfidf_result):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "   # end=len(sorted_scores)\n",
    "    out_list = []\n",
    "    for item in sorted_scores[:10]:\n",
    "        out_list.append(item[0])\n",
    "    return(out_list)\n",
    "            \n",
    "################################################################################################\n",
    "#City1\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = chicago*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'IL'\n",
    "city_to_add['state'] = 'Illinois'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Chicago\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "\n",
    "\n",
    "#code-state=two letters, state=state writte, city=city, category=genre, ranking_value \n",
    "COLUMN_TITLES = ['code','state', 'category', 'ranking_value','City','Top Genre', 'Tags']\n",
    "final_df=pd.DataFrame(columns = COLUMN_TITLES)\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "final_df\n",
    "\n",
    "################################################################################################\n",
    "#City2\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = boston*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'MA'\n",
    "city_to_add['state'] = 'Massachussetts'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Boston\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "\n",
    "top_tags\n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "final_df\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City3\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = miami*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'FL'\n",
    "city_to_add['state'] = 'Florida'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Miami\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "final_df\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = houston*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'TX'\n",
    "city_to_add['state'] = 'Texas'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Houston\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = denver*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'CO'\n",
    "city_to_add['state'] = 'Colorado'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Denver\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = nashville*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'TN'\n",
    "city_to_add['state'] = 'Tennessee'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Nashville\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = denver*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'CO'\n",
    "city_to_add['state'] = 'Colorado'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Denver\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = la*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'CA'\n",
    "city_to_add['state'] = 'California'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Los Angeles\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = nyc*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'NY'\n",
    "city_to_add['state'] = 'New York'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"New York City\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = new_orl*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'LA'\n",
    "city_to_add['state'] = 'Louisiana'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"New Orleans\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#City4\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "la_cities = pheon*1\n",
    "df_la = df.loc[df['city'].isin(la_cities)]\n",
    "df_la.loc[df_la['city'].isin(la_cities), 'city'] = 'Los Angeles'\n",
    "df_la.head()\n",
    "df_la['city'].value_counts()\n",
    "\n",
    "       \n",
    "df_la =explode(df_la.assign(var1=df_la.genres_list.str.split(',')), 'var1')\n",
    "df_la_csv = explode(df_la.assign(var2 = df_la.tags_list.str.split(',')),'var2')\n",
    "df_la[1:5]\n",
    "\n",
    "\n",
    "df_city=df_la_csv*1\n",
    "del df_city['genres_list']\n",
    "del df_city['tags_list']\n",
    "del df_city['city']\n",
    "df_city=df_city.rename(columns={'var1':'genre','var2':'tag'})\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"[\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"]\", \"\")\n",
    "df_city[\"genre\"] = df_city[\"genre\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"[\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"]\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace(\"'\", \"\")\n",
    "df_city[\"tag\"] = df_city[\"tag\"].str.replace('\"', \"\")\n",
    "df_city[\"genre\"]=df_city[\"genre\"].str.lower()\n",
    "df_city[\"tag\"]=df_city[\"tag\"].str.lower()\n",
    "\n",
    "df_city[1:5]\n",
    "\n",
    "#uniques = df_city['genre'].unique()\n",
    "#print(uniques)\n",
    "\n",
    "\n",
    "genres_pivot = df_city.pivot_table('tag',index='genre',aggfunc='count')\n",
    "genres_pivot =  genres_pivot.sort_values('tag', ascending= False)\n",
    "\n",
    "  \n",
    "top_genres = genres_pivot[0:5]\n",
    "genre_cnt=top_genres.ix[0,0]\n",
    "genre_cnt\n",
    "\n",
    "\n",
    "top_genres_list =top_genres.index.tolist() # list of straight up movie_id of the worst movies\n",
    "\n",
    "genre=top_genres_list[0]\n",
    "genre\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#CREATE TOP TAGS\n",
    "tags_top_genre=df_city.query('genre in @top_genres_list')\n",
    "\n",
    "doc = tags_top_genre['tag'].tolist()\n",
    "\n",
    "val_max_feature=200\n",
    "val_min_df=1\n",
    "val_max_df=0.98\n",
    "val_ngram_range=(1,3)\n",
    "\n",
    "top_tags=vector(doc,val_max_feature,val_min_df,val_max_df,val_ngram_range)\n",
    "top_tags\n",
    "#######################################################################################\n",
    "\n",
    "city_to_add = pd.Series()\n",
    "city_to_add['code'] = 'AZ'\n",
    "city_to_add['state'] = 'Arizona'\n",
    "city_to_add['category'] = 'state'\n",
    "city_to_add['ranking_value'] = genre_cnt\n",
    "city_to_add['City'] = \"Pheonix\"\n",
    "city_to_add['Top Genre'] = genre\n",
    "city_to_add['Tags'] = top_tags \n",
    "\n",
    "final_df=final_df.append(city_to_add, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df\n",
    "final_df.to_csv(\"C:/WPI/DS501/CaseStudy/CaseStudy4/city_summary.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>state</th>\n",
       "      <th>category</th>\n",
       "      <th>ranking_value</th>\n",
       "      <th>City</th>\n",
       "      <th>Top Genre</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>state</td>\n",
       "      <td>1351</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>house</td>\n",
       "      <td>[house, techno, tech, remix, deep, music, edm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "      <td>Massachussetts</td>\n",
       "      <td>state</td>\n",
       "      <td>2042</td>\n",
       "      <td>Boston</td>\n",
       "      <td>hip-hop &amp; rap</td>\n",
       "      <td>[hop, rap, hip, hip hop, soul, hip hop rap, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>state</td>\n",
       "      <td>1364</td>\n",
       "      <td>Miami</td>\n",
       "      <td>trance</td>\n",
       "      <td>[trance, progressive, uplifting, uplifting tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>state</td>\n",
       "      <td>854</td>\n",
       "      <td>Houston</td>\n",
       "      <td>hip-hop &amp; rap</td>\n",
       "      <td>[rap, deen, remix, pop, bass, hop, soundcloud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>state</td>\n",
       "      <td>1179</td>\n",
       "      <td>Denver</td>\n",
       "      <td>hip-hop &amp; rap</td>\n",
       "      <td>[trap, rap, hop, hip, hip hop, music, rhymesic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>state</td>\n",
       "      <td>333</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>trap</td>\n",
       "      <td>[rock, hip, music, hip hop, hop, rap, bass, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>state</td>\n",
       "      <td>1179</td>\n",
       "      <td>Denver</td>\n",
       "      <td>hip-hop &amp; rap</td>\n",
       "      <td>[trap, rap, hop, hip, hip hop, music, rhymesic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>state</td>\n",
       "      <td>1577</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>house</td>\n",
       "      <td>[house, techno, pop, remix, tech, tech house, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>state</td>\n",
       "      <td>3174</td>\n",
       "      <td>New York City</td>\n",
       "      <td>house</td>\n",
       "      <td>[house, deep, deep house, music, remix, rap, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>state</td>\n",
       "      <td>824</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>hip-hop &amp; rap</td>\n",
       "      <td>[hip, hip hop, hop, rap, trap, neworleans, atl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>state</td>\n",
       "      <td>801</td>\n",
       "      <td>Pheonix</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>[sundaysample, area13, fly, eighty4, eighty4 f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code           state category ranking_value           City       Top Genre  \\\n",
       "0    IL        Illinois    state          1351        Chicago           house   \n",
       "1    MA  Massachussetts    state          2042         Boston   hip-hop & rap   \n",
       "2    FL         Florida    state          1364          Miami          trance   \n",
       "3    TX           Texas    state           854        Houston   hip-hop & rap   \n",
       "4    CO        Colorado    state          1179         Denver   hip-hop & rap   \n",
       "5    TN       Tennessee    state           333      Nashville            trap   \n",
       "6    CO        Colorado    state          1179         Denver   hip-hop & rap   \n",
       "7    CA      California    state          1577    Los Angeles           house   \n",
       "8    NY        New York    state          3174  New York City           house   \n",
       "9    LA       Louisiana    state           824    New Orleans   hip-hop & rap   \n",
       "10   AZ         Arizona    state           801        Pheonix         hip hop   \n",
       "\n",
       "                                                 Tags  \n",
       "0   [house, techno, tech, remix, deep, music, edm,...  \n",
       "1   [hop, rap, hip, hip hop, soul, hip hop rap, ho...  \n",
       "2   [trance, progressive, uplifting, uplifting tra...  \n",
       "3   [rap, deen, remix, pop, bass, hop, soundcloud,...  \n",
       "4   [trap, rap, hop, hip, hip hop, music, rhymesic...  \n",
       "5   [rock, hip, music, hip hop, hop, rap, bass, in...  \n",
       "6   [trap, rap, hop, hip, hip hop, music, rhymesic...  \n",
       "7   [house, techno, pop, remix, tech, tech house, ...  \n",
       "8   [house, deep, deep house, music, remix, rap, h...  \n",
       "9   [hip, hip hop, hop, rap, trap, neworleans, atl...  \n",
       "10  [sundaysample, area13, fly, eighty4, eighty4 f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=2525.1713615023473, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=933.23076923076928, pvalue=5.8613101238425722e-205)\n",
      "Power_divergenceResult(statistic=1089.0035087719298, pvalue=8.1081209218750301e-239)\n",
      "Power_divergenceResult(statistic=1153.2553191489362, pvalue=8.7981405150267976e-253)\n",
      "Power_divergenceResult(statistic=129.06976744186045, pvalue=6.5475966130439743e-30)\n",
      "Power_divergenceResult(statistic=5057.2545454545452, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=5905.0974025974028, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=2248.8026533996681, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=10839.907180385289, pvalue=0.0)\n",
      "Power_divergenceResult(statistic=1343.8032786885246, pvalue=3.4219627706381781e-294)\n",
      "Power_divergenceResult(statistic=314.70297029702971, pvalue=2.0641378713846243e-70)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({col:np.repeat(df[col].values, df[lst_cols[0]].str.len()) for col in idx_cols}).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}).loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({col:np.repeat(df[col].values, df[lst_cols[0]].str.len()) for col in idx_cols}).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}).append(df.loc[lens==0, idx_cols]).fillna(fill_value).loc[:, df.columns]   \n",
    "      \n",
    "chicago = ['Chicago','Chicago IL and Anaheim Ca','CHICAGO IL, The Almighty WestSide','Chicago Illinois','Chicago, Illinois','Chicago/Albuquerque/Stuttgart','Chicagoland']\n",
    "miami = ['Fort Lauderdale / Miami Beach area in Florida','miami','MIAMI','Miami Beach','Miami Beach - Florida','Miami Beach / Los Angeles /','Miami,Fl']\n",
    "houston = ['Houston','Houston, Texas','Houston ','HOUSTON TEXAS','Houston Tx','houston,texas,united states','Houston`','PORT ARTHUR/HOUSTON/LOS ANGELES/DALLAS/HAMPTON VA.']\n",
    "denver= ['Denver','Denver, CO','Denver','Denver, Colorado']\n",
    "nashville= ['Nashville','Nashville','NASHVILLE, TENNESSEE','Nashville, TN']\n",
    "washington_dc=['Washington DC','Washington, D.C.','Washington D.C.','Washington, DC','Washington D. C.','Washington, D.C','washington,d.c']\n",
    "boston = ['Boston','Boston, Texas','Boston MA ,United states','Boston, Massachusetts - Austin, Texas','Boston, Massachusetts ','BOSTON','Boston, Massachusetts']\n",
    "los_angeles= ['Los Angeles, CA','Los Angeles','L.A','Los Angeles Area','Los Angeles, California','Los Angeles // Santa Barbara','los angeles','Los Angeles, California','LOS ANGELES','LosAngeles','Los Angeles, CA + Phoenix, AZ']\n",
    "new_york_city = ['New York','New York City','NYC','new york city','New York & Philadelphia','New York, NY','NEW YORK','New York/ L.A.','NY']\n",
    "new_orleans = ['New Orleans','New Orleans, Louisiana','The World via New Orleans']\n",
    "pheonix = ['Phoenix','Los Angeles, CA + Phoenix, AZ','Phoenix, AZ']\n",
    "\n",
    "cities = [chicago, miami, houston, denver, nashville, washington_dc, boston, los_angeles, new_york_city, new_orleans, pheonix]\n",
    "df = pd.read_csv('soundcloud.csv')\n",
    "\n",
    "for x in cities:\n",
    "    df_city = df.loc[df['city'].isin(x)]\n",
    "    df_city = explode(df_city.assign(genre = df_city.genres_list.str.split(',')), 'genre')\n",
    "    genre_count = Counter(df_city['genre'])\n",
    "    print(stats.chisquare([genre_count.most_common(1)[0][1], len(df_city['genre'])], [1, len(genre_count)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: The Hacking Part  (20 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Collection\n",
    "* Implement a small Demo/Prototype/experiment result figures for the \"product\" of your data science company. You could use this demo during the Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import soundcloud\n",
    "import pandas as pd\n",
    "\n",
    "client = soundcloud.Client(client_id = 'rTZYCxGbxmlpK8IYRpP6fWGMZXhlgp2z')\n",
    "#rTZYCxGbxmlpK8IYRpP6fWGMZXhlgp2z\n",
    "#2t9loNQH90kzJcsFCODdigxfp325aq4z\n",
    "#cb4917402e7e92b3908cfaf84f52fe45\n",
    "\n",
    "users_to_be_queried = list(map(int, open('users_to_be_queried.txt', 'r').read().split(', ')))\n",
    "soundcloud = pd.read_csv('soundcloud.csv')\n",
    "users_to_be_queried = list(set(users_to_be_queried) - set(soundcloud['user_id']))\n",
    "\n",
    "user_ids = []\n",
    "cities = []\n",
    "genres_list = []\n",
    "tags_list = []\n",
    "\n",
    "for user_id in users_to_be_queried:\n",
    "    favs = client.get('/users/' + str(user_id) + '/favorites')\n",
    "    \n",
    "    if favs:\n",
    "        genres = []\n",
    "        tags = []\n",
    "        \n",
    "        for fav in favs:\n",
    "            if fav.genre:\n",
    "                genres.append(fav.genre)\n",
    "            if fav.tag_list:\n",
    "                tags.append(fav.tag_list)\n",
    "        \n",
    "        user_ids.append(user_id)\n",
    "        user = client.get('/users/' + str(user_id))\n",
    "        cities.append(user.city)\n",
    "\n",
    "        genres_list.append(genres)\n",
    "        tags_list.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soundcloud = pd.read_csv('soundcloud.csv')\n",
    "df = pd.DataFrame({'user_id': user_ids, 'city': cities, 'genres_list': genres_list, 'tags_list': tags_list})\n",
    "df = pd.concat([soundcloud, df])\n",
    "\n",
    "df.to_csv('soundcloud.csv', index = False)\n",
    "\n",
    "users_still_to_be_queried = list(set(users_to_be_queried) - set(df['user_id']))\n",
    "\n",
    "file = open('users_to_be_queried.txt', 'w')\n",
    "for user in users_still_to_be_queried[:-1]:\n",
    "    file.write(str(user) + \", \")\n",
    "file.write(str(users_still_to_be_queried[-1]))\n",
    "file.close()\n",
    "\n",
    "print(df.shape[0])\n",
    "print(len(users_still_to_be_queried))\n",
    "print(df.shape[0] + len(users_still_to_be_queried))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import soundcloud\n",
    "import pandas as pd\n",
    "\n",
    "client = soundcloud.Client(client_id = redacted)\n",
    "\n",
    "us_users = []\n",
    "next_href_exists = True\n",
    "\n",
    "users = client.get('/users', q = 'United States', limit = 200, linked_partitioning = 1)\n",
    "while (len(us_users) <= 10000) and next_href_exists:\n",
    "    users = client.get(users.next_href, q = 'United States', limit = 200, linked_partitioning = 1)\n",
    "    for user in users.collection:\n",
    "        if user.city and ('United States' not in user.city) and (user.country == 'United States'):\n",
    "            us_users.append(user.id)\n",
    "    if 'next_href' not in users.keys():\n",
    "        next_href_exists = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_total = list(map(int, open('users_total.txt', 'r').read().split(', ')))\n",
    "users_total = list(set(us_users + previous_total))\n",
    "\n",
    "file = open('users_total.txt', 'w')\n",
    "for user in users_total[:-1]:\n",
    "    file.write(str(user) + \", \")\n",
    "file.write(str(users_total[-1]))\n",
    "file.close()\n",
    "\n",
    "soundcloud = pd.read_csv('soundcloud.csv')\n",
    "users_to_be_queried = list(set(users_total) - set(soundcloud['user_id']))\n",
    "\n",
    "file = open('users_to_be_queried.txt', 'w')\n",
    "for user in users_to_be_queried[:-1]:\n",
    "    file.write(str(user) + \", \")\n",
    "file.write(str(users_to_be_queried[-1]))\n",
    "file.close()\n",
    "\n",
    "print(soundcloud.shape[0])\n",
    "print(len(users_to_be_queried))\n",
    "print(len(users_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\WPI\\\\DS501\\\\CaseStudy\\\\CaseStudy4\\\\d3-cloropleth-map.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('city_summary.csv')\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "\n",
    "scl = [[0.0, 'rgb(255,237,221)'],[0.2, 'rgb(255,174,104)'],[0.4, 'rgb(255,162,81)'],\\\n",
    "            [0.6, 'rgb(255,157,71)'],[0.8, 'rgb(255,139,38)'],[1.0, 'rgb(255,119,0)']]\n",
    "\n",
    "\n",
    "\n",
    "df['text'] = df['state'] + '<br>' + 'Top City: ' +df['City'] + '<br>' + 'Top Genre:  ' + df['Top Genre'] + '<br>' + 'Tags: ' + df['Tags']\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = df['code'],\n",
    "        z = df['ranking_value'].astype(float),\n",
    "        locationmode = 'USA-states',\n",
    "        text = df['text'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"Ranking Value\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = '2017 Aggregated Soundcloud Listening Data by State<br>(Hover for breakdown)',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "plotly.offline.plot( fig, filename='d3-cloropleth-map.html' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
